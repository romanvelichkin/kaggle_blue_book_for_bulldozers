{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/romanvelichkin/blue-book-for-bulldozers-how-to-get-into-top-25?scriptVersionId=142824922\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Blue Book for Bulldozers\nPredict the auction sale price for a piece of heavy equipment to create a \"blue book\" for bulldozers.\n\nThe goal of the contest is to predict the sale price of a particular piece of heavy equiment at auction based on it's usage, equipment type, and configuaration.  The data is sourced from auction result postings and includes information on usage and equipment configurations.\n\nhttps://www.kaggle.com/competitions/bluebook-for-bulldozers/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Abstract\n\nHere step by step you will learn how to get RMSLE score 0.2415 (top #24) using Random Forest Regressor.  \nYou will be able improve it even further - to 0.2412 (top #23) and probably more.","metadata":{}},{"cell_type":"markdown","source":"### Evaluation\nThe evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n\nSample submission files can be downloaded from the data page. Submission files should be formatted as follows:\n\nHave a header: \"SalesID,SalePrice\";  \nContain two columns:\n- SalesID: SalesID for the validation set in sorted order;\n- SalePrice: Your predicted price of the sale.","metadata":{}},{"cell_type":"markdown","source":"## Prepare tools","metadata":{}},{"cell_type":"code","source":"# import exploratory data analysis and plotting libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# models from scikit-learn\nfrom sklearn.ensemble import RandomForestRegressor\n\n# model evaluations\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:12:33.784268Z","iopub.execute_input":"2022-10-10T13:12:33.785745Z","iopub.status.idle":"2022-10-10T13:12:34.850338Z","shell.execute_reply.started":"2022-10-10T13:12:33.785627Z","shell.execute_reply":"2022-10-10T13:12:34.849083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspect data","metadata":{}},{"cell_type":"code","source":"# Look what files do we have\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:04:48.85986Z","iopub.execute_input":"2022-10-09T16:04:48.860274Z","iopub.status.idle":"2022-10-09T16:04:48.870011Z","shell.execute_reply.started":"2022-10-09T16:04:48.86024Z","shell.execute_reply":"2022-10-09T16:04:48.868711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing training and validation sets\ndf = pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv\", \n                 low_memory=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:12:43.254469Z","iopub.execute_input":"2022-10-10T13:12:43.254958Z","iopub.status.idle":"2022-10-10T13:12:49.345521Z","shell.execute_reply.started":"2022-10-10T13:12:43.254918Z","shell.execute_reply":"2022-10-10T13:12:49.344349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:12:51.349947Z","iopub.execute_input":"2022-10-10T13:12:51.350357Z","iopub.status.idle":"2022-10-10T13:12:52.11667Z","shell.execute_reply.started":"2022-10-10T13:12:51.350321Z","shell.execute_reply":"2022-10-10T13:12:52.115566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:05:27.677174Z","iopub.execute_input":"2022-10-09T16:05:27.677637Z","iopub.status.idle":"2022-10-09T16:05:28.36005Z","shell.execute_reply.started":"2022-10-09T16:05:27.677596Z","shell.execute_reply":"2022-10-09T16:05:28.35861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are lot of missing values.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:05:48.200614Z","iopub.execute_input":"2022-10-09T16:05:48.201135Z","iopub.status.idle":"2022-10-09T16:05:48.212061Z","shell.execute_reply.started":"2022-10-09T16:05:48.201087Z","shell.execute_reply":"2022-10-09T16:05:48.211115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's look how sales and prices look on timeline","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000]);","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:06:15.236122Z","iopub.execute_input":"2022-10-09T16:06:15.236545Z","iopub.status.idle":"2022-10-09T16:06:18.737786Z","shell.execute_reply.started":"2022-10-09T16:06:15.236502Z","shell.execute_reply":"2022-10-09T16:06:18.736482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can't build proper plot because `saledate` is a string-type field. We need to parse dates from it first. We'll do it in next chapter.","metadata":{}},{"cell_type":"code","source":"# Sales prices distribution\ndf.SalePrice.plot.hist();","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:06:53.617085Z","iopub.execute_input":"2022-10-09T16:06:53.617623Z","iopub.status.idle":"2022-10-09T16:06:53.907437Z","shell.execute_reply.started":"2022-10-09T16:06:53.617572Z","shell.execute_reply":"2022-10-09T16:06:53.906195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sales distribution over states\ndf.state.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:07:02.552756Z","iopub.execute_input":"2022-10-09T16:07:02.55318Z","iopub.status.idle":"2022-10-09T16:07:02.5821Z","shell.execute_reply.started":"2022-10-09T16:07:02.553145Z","shell.execute_reply":"2022-10-09T16:07:02.580693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing data","metadata":{}},{"cell_type":"markdown","source":"### Parsing dates\nGet data information from string column and turn it into data format that `pandas` understands. Use `parse_dates` parameter for that.","metadata":{}},{"cell_type":"code","source":"# Import data again but this time parse dates\ndf = pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv\",\n                 low_memory=False,\n                 parse_dates=[\"saledate\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:00.148482Z","iopub.execute_input":"2022-10-10T13:13:00.148873Z","iopub.status.idle":"2022-10-10T13:13:04.481461Z","shell.execute_reply.started":"2022-10-10T13:13:00.148842Z","shell.execute_reply":"2022-10-10T13:13:04.480395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.saledate[:1000]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:08:15.497411Z","iopub.execute_input":"2022-10-09T16:08:15.498201Z","iopub.status.idle":"2022-10-09T16:08:15.657063Z","shell.execute_reply.started":"2022-10-09T16:08:15.498161Z","shell.execute_reply":"2022-10-09T16:08:15.655812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building sales and prices scatter-plot on timeline again","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000]);","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:08:41.641739Z","iopub.execute_input":"2022-10-09T16:08:41.642195Z","iopub.status.idle":"2022-10-09T16:08:41.891185Z","shell.execute_reply.started":"2022-10-09T16:08:41.642155Z","shell.execute_reply":"2022-10-09T16:08:41.88989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look on data again. \n# There are too many columns so I turned dataframe to 90 degrees. \ndf.head().T","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:09:03.001783Z","iopub.execute_input":"2022-10-09T16:09:03.002212Z","iopub.status.idle":"2022-10-09T16:09:03.025319Z","shell.execute_reply.started":"2022-10-09T16:09:03.002175Z","shell.execute_reply":"2022-10-09T16:09:03.024257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sort dataframe by \"saledate\"\nWhen working with time series data, it's a good idea to sort it by date.","metadata":{}},{"cell_type":"code","source":"# Sort dataframe in date order\ndf.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\ndf.saledate.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:12.442878Z","iopub.execute_input":"2022-10-10T13:13:12.443274Z","iopub.status.idle":"2022-10-10T13:13:13.228333Z","shell.execute_reply.started":"2022-10-10T13:13:12.443242Z","shell.execute_reply":"2022-10-10T13:13:13.22722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make copy of dataframe\nWe make a copy of the original dataframe so when manipulate the copy, we'll keep original data.","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:09:49.91787Z","iopub.execute_input":"2022-10-09T16:09:49.918276Z","iopub.status.idle":"2022-10-09T16:09:49.925917Z","shell.execute_reply.started":"2022-10-09T16:09:49.918242Z","shell.execute_reply":"2022-10-09T16:09:49.924258Z"}}},{"cell_type":"code","source":"# Make a copy\ndf_tmp = df.copy()\ndf_tmp","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:16.555534Z","iopub.execute_input":"2022-10-10T13:13:16.556051Z","iopub.status.idle":"2022-10-10T13:13:17.188654Z","shell.execute_reply.started":"2022-10-10T13:13:16.556004Z","shell.execute_reply":"2022-10-10T13:13:17.187524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add datetime parameters for `saledate` column\nWhen we work with time-series data, we want to enrich the time & date component as much as possible.","metadata":{}},{"cell_type":"code","source":"df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\ndf_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\ndf_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\ndf_tmp[\"saleDayOfWeek\"] = df_tmp.saledate.dt.dayofweek\ndf_tmp[\"saleDayOfYear\"] = df_tmp.saledate.dt.dayofyear","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:22.350404Z","iopub.execute_input":"2022-10-10T13:13:22.351051Z","iopub.status.idle":"2022-10-10T13:13:22.573071Z","shell.execute_reply.started":"2022-10-10T13:13:22.351003Z","shell.execute_reply":"2022-10-10T13:13:22.57211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now when we enriched our dataframe with date time features we can drop column \"saledate\"","metadata":{}},{"cell_type":"code","source":"# Drop column \"saledate\"\ndf_tmp.drop(\"saledate\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:23.801806Z","iopub.execute_input":"2022-10-10T13:13:23.802173Z","iopub.status.idle":"2022-10-10T13:13:24.166088Z","shell.execute_reply.started":"2022-10-10T13:13:23.802143Z","shell.execute_reply":"2022-10-10T13:13:24.164937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill missing values\n### Fill missing numeric values","metadata":{}},{"cell_type":"code","source":"for label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:11:16.458877Z","iopub.execute_input":"2022-10-09T16:11:16.459276Z","iopub.status.idle":"2022-10-09T16:11:16.470125Z","shell.execute_reply.started":"2022-10-09T16:11:16.459243Z","shell.execute_reply":"2022-10-09T16:11:16.46897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for which numeric columns have null values\n\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).any():\n            print(label)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:11:27.178521Z","iopub.execute_input":"2022-10-09T16:11:27.178931Z","iopub.status.idle":"2022-10-09T16:11:27.191018Z","shell.execute_reply.started":"2022-10-09T16:11:27.178886Z","shell.execute_reply":"2022-10-09T16:11:27.190017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill numeric values with median\n\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).any():\n            # Add binary column which tells us if data was missing or not\n            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n            # Fill missing numeric values with median\n            df_tmp[label] = content.fillna(content.median())","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:30.330276Z","iopub.execute_input":"2022-10-10T13:13:30.330745Z","iopub.status.idle":"2022-10-10T13:13:30.370965Z","shell.execute_reply.started":"2022-10-10T13:13:30.330708Z","shell.execute_reply":"2022-10-10T13:13:30.369406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if there's still any null numeric values\n\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).any():\n            print(label)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:32.098387Z","iopub.execute_input":"2022-10-10T13:13:32.098857Z","iopub.status.idle":"2022-10-10T13:13:32.110794Z","shell.execute_reply.started":"2022-10-10T13:13:32.098813Z","shell.execute_reply":"2022-10-10T13:13:32.109656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No more nulls in numeric type values.","metadata":{}},{"cell_type":"code","source":"# Check how many examples were missing\ndf_tmp.auctioneerID_is_missing.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:35.23817Z","iopub.execute_input":"2022-10-10T13:13:35.238594Z","iopub.status.idle":"2022-10-10T13:13:35.251736Z","shell.execute_reply.started":"2022-10-10T13:13:35.238559Z","shell.execute_reply":"2022-10-10T13:13:35.250315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tmp.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:12:42.483418Z","iopub.execute_input":"2022-10-09T16:12:42.483821Z","iopub.status.idle":"2022-10-09T16:12:43.286832Z","shell.execute_reply.started":"2022-10-09T16:12:42.483789Z","shell.execute_reply":"2022-10-09T16:12:43.285676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are still null values in dataframe.","metadata":{}},{"cell_type":"markdown","source":"### Filling and turning missing categorical variables into numbers","metadata":{}},{"cell_type":"code","source":"# Check for columns which aren't numeric\nfor label, content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:13:08.051987Z","iopub.execute_input":"2022-10-09T16:13:08.052487Z","iopub.status.idle":"2022-10-09T16:13:08.060144Z","shell.execute_reply.started":"2022-10-09T16:13:08.052446Z","shell.execute_reply":"2022-10-09T16:13:08.059202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How will look state values after turning into numbers\npd.Categorical(df_tmp[\"state\"]).codes","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:13:29.291316Z","iopub.execute_input":"2022-10-09T16:13:29.29173Z","iopub.status.idle":"2022-10-09T16:13:29.339696Z","shell.execute_reply.started":"2022-10-09T16:13:29.291698Z","shell.execute_reply":"2022-10-09T16:13:29.338742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How will look missing values after turning into numbers\npd.Categorical(df_tmp[\"UsageBand\"]).codes","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:13:34.107473Z","iopub.execute_input":"2022-10-09T16:13:34.107965Z","iopub.status.idle":"2022-10-09T16:13:34.150664Z","shell.execute_reply.started":"2022-10-09T16:13:34.10792Z","shell.execute_reply":"2022-10-09T16:13:34.149285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will increase all turned values by 1, so missing values will become 0.","metadata":{}},{"cell_type":"code","source":"# Turn categorical variables into numbers and fill missing\n\nfor label, content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        # Add binart column to indicate whether sample had missing value\n        df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n        # Turn all categories into numbers\n        # Null values will be turned into \"-1\" so we add +1 to all numbers\n        df_tmp[label] = pd.Categorical(content).codes + 1","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:13:40.133999Z","iopub.execute_input":"2022-10-10T13:13:40.13442Z","iopub.status.idle":"2022-10-10T13:13:48.825528Z","shell.execute_reply.started":"2022-10-10T13:13:40.134384Z","shell.execute_reply":"2022-10-10T13:13:48.824269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's look result\ndf_tmp.head().T","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:14:29.504863Z","iopub.execute_input":"2022-10-09T16:14:29.505254Z","iopub.status.idle":"2022-10-09T16:14:29.529713Z","shell.execute_reply.started":"2022-10-09T16:14:29.505222Z","shell.execute_reply":"2022-10-09T16:14:29.528218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if there are still any null values\ndf_tmp.isna().sum().sort_values(\n    ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:14:02.915581Z","iopub.execute_input":"2022-10-10T13:14:02.916043Z","iopub.status.idle":"2022-10-10T13:14:02.99666Z","shell.execute_reply.started":"2022-10-10T13:14:02.916003Z","shell.execute_reply":"2022-10-10T13:14:02.995494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataframe has no null values now.","metadata":{}},{"cell_type":"markdown","source":"## Modelling\n\nWe will use Random Forest Regressor. Because it's a good method to solve regression problems.","metadata":{}},{"cell_type":"code","source":"%%time\n# Let's test what's RFC performance on given data\n\n# Instantiate model\nmodel = RandomForestRegressor(n_jobs=-1,\n                              random_state=42)\n\n# Fit the model\nmodel.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:17:40.857138Z","iopub.execute_input":"2022-10-09T16:17:40.857593Z","iopub.status.idle":"2022-10-09T16:22:45.801301Z","shell.execute_reply.started":"2022-10-09T16:17:40.857555Z","shell.execute_reply":"2022-10-09T16:22:45.80017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Score the model on initial data\nmodel.score(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:23:17.390755Z","iopub.execute_input":"2022-10-09T16:23:17.391184Z","iopub.status.idle":"2022-10-09T16:23:27.185445Z","shell.execute_reply.started":"2022-10-09T16:23:17.391141Z","shell.execute_reply":"2022-10-09T16:23:27.184275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting data into train/validations sets","metadata":{}},{"cell_type":"code","source":"df_tmp.saleYear","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:23:55.325884Z","iopub.execute_input":"2022-10-09T16:23:55.327968Z","iopub.status.idle":"2022-10-09T16:23:55.344787Z","shell.execute_reply.started":"2022-10-09T16:23:55.327874Z","shell.execute_reply":"2022-10-09T16:23:55.343401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training and validation sets\n# Data from 2012 will be used for validation\ndf_val = df_tmp[df_tmp.saleYear == 2012]\ndf_train = df_tmp[df_tmp.saleYear != 2012]\n\nlen(df_train), len(df_val)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:14:14.213697Z","iopub.execute_input":"2022-10-10T13:14:14.214085Z","iopub.status.idle":"2022-10-10T13:14:14.3967Z","shell.execute_reply.started":"2022-10-10T13:14:14.214053Z","shell.execute_reply":"2022-10-10T13:14:14.395527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train and validation sets into X & y\nX_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\nX_val, y_val = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:14:17.082503Z","iopub.execute_input":"2022-10-10T13:14:17.083022Z","iopub.status.idle":"2022-10-10T13:14:17.158335Z","shell.execute_reply.started":"2022-10-10T13:14:17.082973Z","shell.execute_reply":"2022-10-10T13:14:17.15733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:24:06.143351Z","iopub.execute_input":"2022-10-09T16:24:06.143755Z","iopub.status.idle":"2022-10-09T16:24:06.153549Z","shell.execute_reply.started":"2022-10-09T16:24:06.143722Z","shell.execute_reply":"2022-10-09T16:24:06.152411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building an evaluation function","metadata":{}},{"cell_type":"code","source":"# Create evaluation function (the competition uses RMSLE)\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\ndef rmsle(y, y_preds):\n    \"\"\"\n    Calculates root mean squared log error between predictions and true labels.\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y, y_preds))\n\n# Create function to evaluate model using different metrics\ndef show_scores(model):\n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_val)\n    scores = {\"training MAE\": mean_absolute_error(y_train, train_preds),\n              \"validation MAE\": mean_absolute_error(y_val, val_preds),\n              \"training RMSLE\": rmsle(y_train, train_preds),\n              \"validation RMSLE\": rmsle(y_val, val_preds),\n              \"training R^2\": r2_score(y_train, train_preds),\n              \"validation R^2\": r2_score(y_val, val_preds)\n             }\n    return scores","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:14:26.589818Z","iopub.execute_input":"2022-10-10T13:14:26.590303Z","iopub.status.idle":"2022-10-10T13:14:26.600635Z","shell.execute_reply.started":"2022-10-10T13:14:26.590263Z","shell.execute_reply":"2022-10-10T13:14:26.599509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing our model on a subset","metadata":{}},{"cell_type":"code","source":"# Change max samples value\nmodel = RandomForestRegressor(n_jobs=-1,\n                              random_state=42,\n                              max_samples=10000)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:24:40.148769Z","iopub.execute_input":"2022-10-09T16:24:40.149222Z","iopub.status.idle":"2022-10-09T16:24:40.155236Z","shell.execute_reply.started":"2022-10-09T16:24:40.149185Z","shell.execute_reply":"2022-10-09T16:24:40.15406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:24:42.972423Z","iopub.execute_input":"2022-10-09T16:24:42.972806Z","iopub.status.idle":"2022-10-09T16:24:56.490298Z","shell.execute_reply.started":"2022-10-09T16:24:42.972772Z","shell.execute_reply":"2022-10-09T16:24:56.489183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_scores(model)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:25:16.863365Z","iopub.execute_input":"2022-10-09T16:25:16.863761Z","iopub.status.idle":"2022-10-09T16:25:23.519191Z","shell.execute_reply.started":"2022-10-09T16:25:16.863727Z","shell.execute_reply":"2022-10-09T16:25:23.517937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even without tuning Random Forest Regressor gives us result that could get at least Bronze medal. ","metadata":{}},{"cell_type":"markdown","source":"### Hyperparameters tuning with RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Different RandomForestRegressor hyperparameters\nrf_grid = {\"n_estimators\": [30, 40, 50],\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": [10, 14, 18],\n           \"min_samples_leaf\": [1, 2, 3],\n           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n           \"max_samples\": [10000]}\n\n# Instantiate RandomiedSearchCV model\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                   random_state=42),\n                                                   param_distributions=rf_grid,\n                                                   n_iter=10,\n                                                   cv=5,\n                                                   verbose=True)\n\nrs_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:25:42.103652Z","iopub.execute_input":"2022-10-09T16:25:42.104734Z","iopub.status.idle":"2022-10-09T16:29:37.195163Z","shell.execute_reply.started":"2022-10-09T16:25:42.104693Z","shell.execute_reply":"2022-10-09T16:29:37.193868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the best model hyperparameters\nrs_model.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:30:06.253908Z","iopub.execute_input":"2022-10-09T16:30:06.254385Z","iopub.status.idle":"2022-10-09T16:30:06.263296Z","shell.execute_reply.started":"2022-10-09T16:30:06.25433Z","shell.execute_reply":"2022-10-09T16:30:06.262107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the RandomizedSearh model\nshow_scores(rs_model)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T16:30:08.669523Z","iopub.execute_input":"2022-10-09T16:30:08.669982Z","iopub.status.idle":"2022-10-09T16:30:12.427165Z","shell.execute_reply.started":"2022-10-09T16:30:08.669935Z","shell.execute_reply":"2022-10-09T16:30:12.425882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters tuning with GridSearchCV","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Different RandomForestRegressor hyperparameters\nrf_grid = {\"n_estimators\": [170, 200],\n           \"min_samples_split\": [4, 5],\n           \"min_samples_leaf\": [2],\n           \"max_features\": [0.4, 0.45, 0.5],\n           \"max_samples\": [10000]}\n\n# Instantiate GridSearchCV model\ngs_model = GridSearchCV(RandomForestRegressor(n_jobs=-1,\n                                              random_state=42),\n                                              param_grid=rf_grid,\n                                              cv=5,\n                                              verbose=True)\n\ngs_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:43:16.525428Z","iopub.execute_input":"2022-10-10T13:43:16.526338Z","iopub.status.idle":"2022-10-10T13:59:07.857806Z","shell.execute_reply.started":"2022-10-10T13:43:16.526291Z","shell.execute_reply":"2022-10-10T13:59:07.856305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the best model hyperparameters\ngs_model.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:12:38.35432Z","iopub.execute_input":"2022-10-10T14:12:38.354892Z","iopub.status.idle":"2022-10-10T14:12:38.364599Z","shell.execute_reply.started":"2022-10-10T14:12:38.354839Z","shell.execute_reply":"2022-10-10T14:12:38.362718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the GridSearh model\nshow_scores(gs_model)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:12:43.816334Z","iopub.execute_input":"2022-10-10T14:12:43.817044Z","iopub.status.idle":"2022-10-10T14:12:54.282461Z","shell.execute_reply.started":"2022-10-10T14:12:43.816982Z","shell.execute_reply":"2022-10-10T14:12:54.279096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train a model with the best hyperparameters\nI've tuned hyperparameters by hand and improved final result.","metadata":{}},{"cell_type":"code","source":"%%time\n\n# I've tuned hyperparameters by hand a bit\n# Best hyperparameters\nbest_model = RandomForestRegressor(min_samples_leaf=2,\n                                   min_samples_split=5,\n                                   n_estimators=200,\n                                   max_features=0.45,\n                                   n_jobs=-1,\n                                   max_samples=None,\n                                   random_state=42)\n\n#Fit the model with those hyperparameters\nbest_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:18:17.51016Z","iopub.execute_input":"2022-10-10T13:18:17.510621Z","iopub.status.idle":"2022-10-10T13:22:30.310229Z","shell.execute_reply.started":"2022-10-10T13:18:17.510583Z","shell.execute_reply":"2022-10-10T13:22:30.30886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can try to increase `n_estimators`. At some range it will improve score. However it will slow down training model drastically.\n\n`n_estimators=500` gave me RMSLE = 0.2414  \n`n_estimators=5000` gave me RMSLE = 0.2412, but it took an hour to train model on my PC. Training it here on Kaggle could take times more.\n","metadata":{}},{"cell_type":"code","source":"# Scores for best model trained on all the data\nshow_scores(best_model)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T13:22:35.759177Z","iopub.execute_input":"2022-10-10T13:22:35.760276Z","iopub.status.idle":"2022-10-10T13:22:51.161357Z","shell.execute_reply.started":"2022-10-10T13:22:35.760233Z","shell.execute_reply":"2022-10-10T13:22:51.160071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions on test data","metadata":{}},{"cell_type":"code","source":"# Import the test data\ndf_test = pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/Test.csv\",\n                      low_memory=False,\n                      parse_dates=[\"saledate\"])\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:15:26.504593Z","iopub.execute_input":"2022-10-10T14:15:26.505228Z","iopub.status.idle":"2022-10-10T14:15:26.727385Z","shell.execute_reply.started":"2022-10-10T14:15:26.505186Z","shell.execute_reply":"2022-10-10T14:15:26.725947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:15:35.296363Z","iopub.execute_input":"2022-10-10T14:15:35.296829Z","iopub.status.idle":"2022-10-10T14:15:35.332175Z","shell.execute_reply.started":"2022-10-10T14:15:35.296793Z","shell.execute_reply":"2022-10-10T14:15:35.330781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test data has nulls so we need to deal with it.","metadata":{}},{"cell_type":"markdown","source":"### Preprocessing test data (getting it into same format as training dataset)","metadata":{}},{"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Performs transformation on df and returns transformed df\n    \"\"\"\n    # Enrich dataframe with date time features\n    df[\"saleYear\"] = df.saledate.dt.year\n    df[\"saleMonth\"] = df.saledate.dt.month\n    df[\"saleDay\"] = df.saledate.dt.day\n    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n\n    # Now when we enriched our dataframe with date time features we can drop column \"saledate\"\n    df.drop(\"saledate\", axis=1, inplace=True)\n\n    # Fill numeric values with median\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                # Add binary column which tells us if data was misasing or not\n                df[label+\"_is_missing\"] = pd.isnull(content)\n                # Fill missing numeric values with median\n                df[label] = content.fillna(content.median())\n\n    # Turn categorical variables into numbers and fill missing\n        if not pd.api.types.is_numeric_dtype(content):\n            # Add binart column to indicate whether sample had missing value\n            df[label+\"_is_missing\"] = pd.isnull(content)\n            # Turn missing categories into number and add +1\n            df[label] = pd.Categorical(content).codes + 1\n            \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:16:30.358556Z","iopub.execute_input":"2022-10-10T14:16:30.358968Z","iopub.status.idle":"2022-10-10T14:16:30.369377Z","shell.execute_reply.started":"2022-10-10T14:16:30.358935Z","shell.execute_reply":"2022-10-10T14:16:30.368389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = preprocess_data(df_test)\ndf_test.head().T","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:16:40.527652Z","iopub.execute_input":"2022-10-10T14:16:40.52803Z","iopub.status.idle":"2022-10-10T14:16:40.776372Z","shell.execute_reply.started":"2022-10-10T14:16:40.527999Z","shell.execute_reply":"2022-10-10T14:16:40.77503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In test dataset doesn't have nulls in `auctioneerID` column. As result preprocessed test dataset won't have `auctioneerID_is_missing` column. ","metadata":{}},{"cell_type":"code","source":"# We can find how the columns differ using sets\nset(X_train.columns) - set(df_test.columns)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:16:56.076949Z","iopub.execute_input":"2022-10-10T14:16:56.077425Z","iopub.status.idle":"2022-10-10T14:16:56.085633Z","shell.execute_reply.started":"2022-10-10T14:16:56.077379Z","shell.execute_reply":"2022-10-10T14:16:56.084499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Manually adjust df_test to have `auctioneerID_is_missing` column.\n","metadata":{}},{"cell_type":"code","source":"# Adding auctioneerID_is_missing column\ndf_test[\"auctioneerID_is_missing\"] = False\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:19:49.780037Z","iopub.execute_input":"2022-10-10T14:19:49.780563Z","iopub.status.idle":"2022-10-10T14:19:49.811172Z","shell.execute_reply.started":"2022-10-10T14:19:49.780521Z","shell.execute_reply":"2022-10-10T14:19:49.809843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making predictions on test data","metadata":{}},{"cell_type":"code","source":"# Make predictions on test data\ntest_preds = best_model.predict(df_test)\n\ntest_preds","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:20:09.838541Z","iopub.execute_input":"2022-10-10T14:20:09.838963Z","iopub.status.idle":"2022-10-10T14:20:10.236024Z","shell.execute_reply.started":"2022-10-10T14:20:09.838929Z","shell.execute_reply":"2022-10-10T14:20:10.234966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Format prediction into the same format Kaggle is after\ndf_preds = pd.DataFrame()\ndf_preds[\"SalesID\"] = df_test[\"SalesID\"]\ndf_preds[\"SalePrice\"] = test_preds\ndf_preds","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:20:48.699634Z","iopub.execute_input":"2022-10-10T14:20:48.700053Z","iopub.status.idle":"2022-10-10T14:20:48.72008Z","shell.execute_reply.started":"2022-10-10T14:20:48.70002Z","shell.execute_reply":"2022-10-10T14:20:48.718601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you need, you can export predictions.","metadata":{}},{"cell_type":"code","source":"# Export prediction data\n# You can uncomment it\n# df_preds.to_csv(\"/kaggle/input/bluebook-for-bulldozers/test_prediction.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance","metadata":{}},{"cell_type":"code","source":"# Find feature importance of best model\nbest_model.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:22:30.599719Z","iopub.execute_input":"2022-10-10T14:22:30.600671Z","iopub.status.idle":"2022-10-10T14:22:30.913295Z","shell.execute_reply.started":"2022-10-10T14:22:30.600614Z","shell.execute_reply":"2022-10-10T14:22:30.911912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataframe with feature importances\nfeatures = (pd.DataFrame({\"features\": df_test.columns,\n                          \"feature_importances\": best_model.feature_importances_})\n            .sort_values(\"feature_importances\", ascending=False)\n            .reset_index(drop=True))\n\nfeatures","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:22:39.379474Z","iopub.execute_input":"2022-10-10T14:22:39.379904Z","iopub.status.idle":"2022-10-10T14:22:39.706666Z","shell.execute_reply.started":"2022-10-10T14:22:39.379869Z","shell.execute_reply":"2022-10-10T14:22:39.704673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the dataframe\nfig, ax = plt.subplots(figsize=(10,20))\nax.barh(features[\"features\"][:50], features[\"feature_importances\"][:50])\nax.set_ylabel(\"Features\")\nax.set_xlabel(\"Feature importance\");","metadata":{"execution":{"iopub.status.busy":"2022-10-10T14:22:52.572521Z","iopub.execute_input":"2022-10-10T14:22:52.573047Z","iopub.status.idle":"2022-10-10T14:22:54.167231Z","shell.execute_reply.started":"2022-10-10T14:22:52.573006Z","shell.execute_reply":"2022-10-10T14:22:54.165039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result\n\nWe've improved our data by enriching it with date and time features. We also dealt with `null` values.\nAs result we trained model with RMSLE score 0.2415 (top #24) and found way to improve it further - to 0.2412 (top #23).\n\nAlso we ranked features by its importance. `YearMade` and `ProductSize` are by far most important features.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}